{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da565f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd5862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "LANGSMITH_TRACING=\"true\"\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_API_KEY= os.getenv(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a69741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dfaa199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a867540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model_name=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a92176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db5d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "        \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "        \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "        ]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=25\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926d7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(retriever,\n",
    "                      \"retrieve_blog_posts\",\n",
    "                      \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.You are a specialized assistant. Use the 'retriever_tool' **only** when the query explicitly relates to LangChain blog data. For all other queries, respond directly without using any tool. For simple queries like 'hi', 'hello', or 'how are you', provide a normal response.\")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d0015dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevence check on retrieved documents.\"\"\"\n",
    "    \n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevent to the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95bfd0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8593389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a grader checking if a document is relevant to a user's question. The check has to be done very strictly.\n",
    "If the document has words or meanings related to the question, mark it as relevant.\n",
    "Give a simple 'yes' or 'no' answer to show if the document is relevant or not.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672bdf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikas Chauhan\\AppData\\Local\\Temp\\ipykernel_7908\\4001347186.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(question)\n"
     ]
    }
   ],
   "source": [
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d9a2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.'),\n",
       " Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'),\n",
       " Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4c1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt = docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11213f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "607b44cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69bc77ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "question = \"who is elon musk?\"\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94f10c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "518bad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The agent's memory is composed of both short-term memory, which enables in-context learning, and long-term memory, which allows it to retain and recall information over extended periods.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 1900, 'total_tokens': 1936, 'completion_time': 0.03, 'prompt_time': 0.235300116, 'queue_time': 0.250600974, 'total_time': 0.265300116}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run--d82233f7-7f3c-4c6b-bd7a-99eca5b01435-0', usage_metadata={'input_tokens': 1900, 'output_tokens': 36, 'total_tokens': 1936})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"agent memory\"\n",
    "generation = rag_chain.invoke({\"context\":docs, \"question\": question})\n",
    "generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "    \n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "569be712",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm_grader_hall = llm.with_structured_output(GradeHallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a grader checking if an LLM generation is grounded in or supported by a set of retrieved facts.\n",
    "Give a simple 'yes' or 'no' answer. 'Yes' means the generation is grounded in or supported by a set of retrieved the facts.\"\"\"\n",
    "\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_grader = hallucination_prompt | structured_llm_grader_hall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "355bc3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.'),\n",
       " Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'),\n",
       " Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "678b55bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The agent's memory is composed of both short-term memory, which enables in-context learning, and long-term memory, which allows it to retain and recall information over extended periods.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 1900, 'total_tokens': 1936, 'completion_time': 0.03, 'prompt_time': 0.235300116, 'queue_time': 0.250600974, 'total_time': 0.265300116}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run--d82233f7-7f3c-4c6b-bd7a-99eca5b01435-0', usage_metadata={'input_tokens': 1900, 'output_tokens': 36, 'total_tokens': 1936})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': 'yes'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhallucination_grader\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgeneration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:371\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     **kwargs: Any,\n\u001b[32m    367\u001b[39m ) -> BaseMessage:\n\u001b[32m    368\u001b[39m     config = ensure_config(config)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    370\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    381\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:956\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    949\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    953\u001b[39m     **kwargs: Any,\n\u001b[32m    954\u001b[39m ) -> LLMResult:\n\u001b[32m    955\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:775\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    774\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m         )\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1021\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1019\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:498\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    494\u001b[39m params = {\n\u001b[32m    495\u001b[39m     **params,\n\u001b[32m    496\u001b[39m     **kwargs,\n\u001b[32m    497\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:355\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    222\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    223\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\_base_client.py:1222\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1210\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1217\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1218\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1219\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1220\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1221\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\_base_client.py:1031\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m             err.response.read()\n\u001b[32m   1030\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': 'yes'}}"
     ]
    }
   ],
   "source": [
    "print(hallucination_grader.invoke({\"documents\": docs, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6947a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "    \n",
    "    binary_score: str = Field(\n",
    "        description= \"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm_grader_ans = llm.with_structured_output(GradeAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39659b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a gender assessing whether an answer addresses / resolves a question \\n\n",
    "Give a binary score 'yes' or 'no'. 'yes' means that the answer resolves the question.\"\"\"\n",
    "\n",
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e86e740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_grader = answer_prompt | structured_llm_grader_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faabeaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "print(answer_grader.invoke({\"question\": question, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c3bad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a question re-writer that converts an input question into a better optimized version for vector store retrieval document.\n",
    "You are given both a question and a document.\n",
    "- First, check if the question is relevant to the document by identifying a connection or relevance between them.\n",
    "- If there is a little relevancy, rewrite the question based on the semantic intect of the question and the context of the document.\n",
    "- If no relevance is found, simply return this single word \"question not relevant.\" dont return the entire phrase\n",
    "Your goal is to ensure the rewritten question aligns well with the document for better retrieval.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "393876a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_write_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"\"\"Here is the initial question: \\n\\n {question} \\n,\n",
    "     Here is the document: \\n\\n {documents} \\n ,\n",
    "     Formulate an improved question. If possible other return 'question not relevant'.\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8166c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f2e383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"who is the current indian prime minister?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb0c6d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The initial question is \"Who is the current Indian prime minister?\"\\n\\nAfter analyzing the provided document, I found that it is not relevant to the question. The document discusses LLM-powered autonomous agents, their components, and their capabilities. It does not mention anything about the current Indian prime minister.\\n\\nTherefore, I will return the simplified answer: \"question not relevant\".'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_rewriter.invoke({\"question\":question,\"documents\":docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f66383a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    filter_documents: List[str]\n",
    "    unfilter_documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd02fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: AgentState):\n",
    "    print(\"-----RETRIEVE-----\")\n",
    "    question = state['question']\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "410da489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state: AgentState):\n",
    "    print(\"-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\")\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    filtered_docs = []\n",
    "    unfiltered_docs = []\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke({\"question\":question, \"document\":doc})\n",
    "        grade = score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"-----GRADE: DOCUMENT RELEVANT-----\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\"-----GRADE: DOCUMENT NOT RELEVANT-----\")\n",
    "            unfiltered_docs.append(doc)\n",
    "    if len(unfiltered_docs)>1:\n",
    "        return {\"unfilter_documents\": unfiltered_docs, \"filter_documents\":[], \"question\":question}\n",
    "    else:\n",
    "        return {\"unfilter_documents\": [], \"filter_documents\": filtered_docs, \"question\":question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb8b35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state: AgentState):\n",
    "    print(\"-----ACCESS GRADED DOCUMENTS-----\")\n",
    "    question = state[\"question\"]\n",
    "    unfiltered_documents = state[\"unfilter_documents\"]\n",
    "    filtered_documents = state[\"filter_documents\"]\n",
    "    \n",
    "    if unfiltered_documents:\n",
    "        print(\"-----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY-----\")\n",
    "        return \"transform_query\"\n",
    "    if filtered_documents:\n",
    "        print(\"-----DECISION: GENERATE-----\")\n",
    "        return \"generate\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcf14106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:AgentState):\n",
    "    print(\"-----GENERATE-----\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    generation = rag_chain.invoke({\"context\":documents, \"question\":question})\n",
    "    return {\"documents\": documents, \"question\":question, \"generation\":generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54644dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state:AgentState):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    print(f\"this is my documents{documents}\")\n",
    "    response = question_rewriter.invoke({\"question\":question, \"documents\":documents})\n",
    "    print(f\"-----RESPONSE----- {response}\")\n",
    "    if response == 'question not relevant':\n",
    "        print(\"-----QUESTION IS NOT AT ALL RELEVANT-----\")\n",
    "        return {\"documents\":documents, \"question\": response, \"generation\": \"question was not at all relevant\"}\n",
    "    else:\n",
    "        return {\"documents\":documents, \"question\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "751b24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate_after_transformation(state:AgentState):\n",
    "    question = state[\"question\"]\n",
    "    if question == \"question not relevant\":\n",
    "        return \"query_not_at_all_relevant\"\n",
    "    else:\n",
    "        return \"Retriever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca6de43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_vs_documents_and_question(state:AgentState):\n",
    "    print(\"-----CHECK HELLUCINATIONS-----\")\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    generation = state['generation']\n",
    "    \n",
    "    score = hallucination_grader.invoke({\"documents\":documents, \"generation\":generation})\n",
    "    \n",
    "    grade = score.binary_score\n",
    "    \n",
    "    if grade == 'yes':\n",
    "        print(\"-----DECISION: GENERATION IS GROUNDED IN DOCUMENTS-----\")\n",
    "        print(\"-----GRADE GENERATION vs QUESTION-----\")\n",
    "        score = answer_grader.invoke({\"question\":question, \"generation\":generation})\n",
    "        \n",
    "        grade = score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"-----DECISION: GENERATION ADDRESS THE QUESTION-----\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"-----DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "            return \"not useful\"        \n",
    "    else:\n",
    "        pprint(\"-----DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "        \"not useful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d16c8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Docs_Vector_Retrieve\", retrieve)\n",
    "workflow.add_node(\"Grading_Generated_Documents\", grade_documents)\n",
    "workflow.add_node(\"Content_Generator\", generate)\n",
    "workflow.add_node(\"Transform_User_Query\", transform_query)\n",
    "workflow.add_edge(START,\"Docs_Vector_Retrieve\")\n",
    "workflow.add_edge(\"Docs_Vector_Retrieve\", \"Grading_Generated_Documents\")\n",
    "workflow.add_conditional_edges(\"Grading_Generated_Documents\", decide_to_generate, \n",
    "                               {\"generate\":\"Content_Generator\", \"transform_query\":\"Transform_User_Query\"})\n",
    "workflow.add_conditional_edges(\"Content_Generator\", grade_generation_vs_documents_and_question, \n",
    "                               {\"useful\": END, \"not_useful\": \"Transform_User_Query\"})\n",
    "workflow.add_conditional_edges(\"Transform_User_Query\", decide_to_generate_after_transformation, \n",
    "                               {\"Retriever\": \"Docs_Vector_Retrieve\", \"query_not_at_all_relevant\": END})\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ca341d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecd4a1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY-----\n",
      "this is my documents[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'), Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.'), Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')]\n",
      "-----RESPONSE----- After analyzing the question and the provided documents, I found that the question \"Explain how the different types of agent memory work?\" has some relevance to the documents.\n",
      "\n",
      "The documents describe various aspects of agent memory, including short-term memory, long-term memory, and tool use. The question seems to be focusing on the different types of memory used in agent systems, which is partially addressed in the documents.\n",
      "\n",
      "To improve the question, I would rephrase it to make it more specific and relevant to the context of the documents. Here's a rewritten question:\n",
      "\n",
      "\"What are the key differences between short-term memory, long-term memory, and tool use in the context of LLM-powered autonomous agents?\"\n",
      "\n",
      "This rewritten question is more specific and targeted to the context of the documents, which provides a clear understanding of the different types of memory used in LLM-powered autonomous agents.\n",
      "\n",
      "However, if the question were to be phrased differently, such as \"Explain the concept of agent memory in general\", it would be less relevant to the provided documents, and I would return the phrase \"question not relevant\".\n",
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----DECISION: GENERATE-----\n",
      "-----GENERATE-----\n",
      "-----CHECK HELLUCINATIONS-----\n",
      "-----DECISION: GENERATION IS GROUNDED IN DOCUMENTS-----\n",
      "-----GRADE GENERATION vs QUESTION-----\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': 'yes'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mExplain how the different types of agent memory work?\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2823\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2820\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2821\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2823\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2833\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2834\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2835\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2836\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2837\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:153\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    151\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:625\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\graph\\branch.py:173\u001b[39m, in \u001b[36mBranch._route\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    172\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    372\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mgrade_generation_vs_documents_and_question\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-----DECISION: GENERATION IS GROUNDED IN DOCUMENTS-----\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-----GRADE GENERATION vs QUESTION-----\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m score = \u001b[43manswer_grader\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgeneration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m grade = score.binary_score\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grade==\u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:371\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     **kwargs: Any,\n\u001b[32m    367\u001b[39m ) -> BaseMessage:\n\u001b[32m    368\u001b[39m     config = ensure_config(config)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    370\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    381\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:956\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    949\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    953\u001b[39m     **kwargs: Any,\n\u001b[32m    954\u001b[39m ) -> LLMResult:\n\u001b[32m    955\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:775\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    774\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m         )\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1021\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1019\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:498\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    494\u001b[39m params = {\n\u001b[32m    495\u001b[39m     **params,\n\u001b[32m    496\u001b[39m     **kwargs,\n\u001b[32m    497\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:355\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    222\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    223\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\_base_client.py:1222\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1210\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1217\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1218\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1219\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1220\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1221\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\_base_client.py:1031\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m             err.response.read()\n\u001b[32m   1030\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': 'yes'}}",
      "During task with name 'Content_Generator' and id 'c31e97de-5ad1-da56-1a66-baca51bbad84'"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Explain how the different types of agent memory work?\"}\n",
    "app.invoke(inputs)['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64e429a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY-----\n",
      "this is my documents[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'language': 'en', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.'}, page_content='Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Weng, Lilian. (Mar 2023). Prompt Engineering. Lil’Log. https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.'), Document(metadata={'title': \"Prompt Engineering | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.'}, page_content='year    = \"2023\",\\n  month   = \"Mar\",\\n  url     = \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\\n}\\nUseful Resources#'), Document(metadata={'title': \"Prompt Engineering | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.'}, page_content=\"Prompt Engineering | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\")]\n",
      "-----RESPONSE----- The relevancy check shows that the question \"who is a prompt engineering?\" is related to the document, which discusses the concept of prompt engineering. The document provides a detailed explanation of prompt engineering, its methods, and its goals.\n",
      "\n",
      "To formulate an improved question, I will rephrase the original question to better align with the content of the document:\n",
      "\n",
      "\"What are the methods and goals of prompt engineering?\"\n",
      "\n",
      "This rewritten question is more specific and relevant to the topic of the document, which makes it more suitable for vector store retrieval.\n",
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----DECISION: GENERATE-----\n",
      "-----GENERATE-----\n",
      "-----CHECK HELLUCINATIONS-----\n",
      "-----DECISION: GENERATION IS GROUNDED IN DOCUMENTS-----\n",
      "-----GRADE GENERATION vs QUESTION-----\n",
      "-----DECISION: GENERATION ADDRESS THE QUESTION-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='According to the document, the methods of prompt engineering aim to communicate with LLM to steer its behavior for desired outcomes without updating the model weights, and the effect of these methods can vary greatly among models. The goal of prompt engineering is about alignment and model steerability, requiring heavy experimentation and heuristics.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 1144, 'total_tokens': 1207, 'completion_time': 0.0525, 'prompt_time': 0.142816943, 'queue_time': 0.24725556699999998, 'total_time': 0.195316943}, 'model_name': 'Llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run--c18bb424-5d9e-4c62-85f7-addac5c4385a-0', usage_metadata={'input_tokens': 1144, 'output_tokens': 63, 'total_tokens': 1207})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"who is a prompt engineering?\"}\n",
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15b1450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what is role of data structure while creating ai agentic pattern?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "763007b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY-----\n",
      "this is my documents[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content=\"Planning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\"), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The generative agent architecture. (Image source: Park et al. 2023)'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')]\n",
      "-----RESPONSE----- After analyzing the question and the document, I can see that there is a connection between the two. The question is about the role of data structures while creating AI agent patterns, and the document discusses the concepts of planning, memory, and tool use in LLM-powered autonomous agents.\n",
      "\n",
      "Based on this connection, I can rewrite the question to make it more relevant and aligned with the document:\n",
      "\n",
      "\"What is the significance of data structures in planning and memory management for LLM-powered autonomous agents?\"\n",
      "\n",
      "This rewritten question takes into account the concepts presented in the document and frames the question in a way that is more relevant to the content.\n",
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----DECISION: GENERATE-----\n",
      "-----GENERATE-----\n",
      "-----CHECK HELLUCINATIONS-----\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': 'yes'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2823\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2820\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2821\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2823\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2833\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2834\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2835\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2836\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2837\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:153\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    151\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:625\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\graph\\branch.py:173\u001b[39m, in \u001b[36mBranch._route\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    172\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    372\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mgrade_generation_vs_documents_and_question\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      4\u001b[39m documents = state[\u001b[33m'\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m generation = state[\u001b[33m'\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m score = \u001b[43mhallucination_grader\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgeneration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m grade = score.binary_score\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grade == \u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:371\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     **kwargs: Any,\n\u001b[32m    367\u001b[39m ) -> BaseMessage:\n\u001b[32m    368\u001b[39m     config = ensure_config(config)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    370\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    381\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:956\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    949\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    953\u001b[39m     **kwargs: Any,\n\u001b[32m    954\u001b[39m ) -> LLMResult:\n\u001b[32m    955\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:775\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    774\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m         )\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1021\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1019\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:498\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    494\u001b[39m params = {\n\u001b[32m    495\u001b[39m     **params,\n\u001b[32m    496\u001b[39m     **kwargs,\n\u001b[32m    497\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:355\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    222\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    223\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\_base_client.py:1222\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1210\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1217\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1218\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1219\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1220\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1221\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\_base_client.py:1031\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m             err.response.read()\n\u001b[32m   1030\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': 'yes'}}",
      "During task with name 'Content_Generator' and id 'af8701cd-1f9e-8925-9786-1cc45b2b8367'"
     ]
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dee3fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY-----\n",
      "this is my documents[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='},\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#')]\n",
      "-----RESPONSE----- The initial question is: \"what is role of c language and php while creating ai agentic pattern?\"\n",
      "\n",
      "After analyzing the document, I found that the document is about LLM (Large Language Model) powered autonomous agents and their components, such as planning, memory, and tool use. The document does not mention C language or PHP in the context of creating AI agentic patterns.\n",
      "\n",
      "However, I noticed that the document does mention the use of external APIs and code execution capability, which could be related to programming languages. But the connection between C language, PHP, and AI agentic patterns is not explicitly mentioned in the document.\n",
      "\n",
      "Considering the relevance, I will rephrase the question to focus on the main topic of the document, which is LLM-powered autonomous agents and their components. Here is the rewritten question:\n",
      "\n",
      "\"What is the role of planning and memory components in an LLM-powered autonomous agent system?\"\n",
      "\n",
      "This rewritten question is more relevant to the document and focuses on the main topic, which is AI agentic patterns and their components.\n",
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----GRADE: DOCUMENT NOT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY-----\n",
      "this is my documents[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='},\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'), Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Posts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='\"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such')]\n",
      "-----RESPONSE----- Based on the provided document, I rephrased the question to focus on the main topic of LLM-powered autonomous agents and their components. Here is the rewritten question:\n",
      "\n",
      "\"What is the role of planning and memory components in an LLM-powered autonomous agent system?\"\n",
      "\n",
      "This rewritten question is more relevant to the document and focuses on the main topic, which is AI agentic patterns and their components.\n",
      "-----RETRIEVE-----\n",
      "-----CHECK DOCUMENTS RELEVANCE TO THE QUESTION-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----GRADE: DOCUMENT RELEVANT-----\n",
      "-----ACCESS GRADED DOCUMENTS-----\n",
      "-----DECISION: GENERATE-----\n",
      "-----GENERATE-----\n",
      "-----CHECK HELLUCINATIONS-----\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': 'yes'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mwhat is role of c language and php while creating ai agentic pattern?\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2823\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2820\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2821\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2823\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2833\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2834\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2835\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2836\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2837\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:153\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    151\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:625\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\graph\\branch.py:173\u001b[39m, in \u001b[36mBranch._route\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    172\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    372\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mgrade_generation_vs_documents_and_question\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      4\u001b[39m documents = state[\u001b[33m'\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m generation = state[\u001b[33m'\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m score = \u001b[43mhallucination_grader\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgeneration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m grade = score.binary_score\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grade == \u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:371\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     **kwargs: Any,\n\u001b[32m    367\u001b[39m ) -> BaseMessage:\n\u001b[32m    368\u001b[39m     config = ensure_config(config)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    370\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    381\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:956\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    949\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    953\u001b[39m     **kwargs: Any,\n\u001b[32m    954\u001b[39m ) -> LLMResult:\n\u001b[32m    955\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:775\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    774\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m         )\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1021\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1019\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:498\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    494\u001b[39m params = {\n\u001b[32m    495\u001b[39m     **params,\n\u001b[32m    496\u001b[39m     **kwargs,\n\u001b[32m    497\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:355\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    222\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    223\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    353\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\_base_client.py:1222\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1210\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1217\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1218\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1219\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1220\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1221\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\learning\\learn_langgraph_ss\\venv\\Lib\\site-packages\\groq\\_base_client.py:1031\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m             err.response.read()\n\u001b[32m   1030\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': 'yes'}}",
      "During task with name 'Content_Generator' and id 'd38c0b6e-70ec-68b3-4275-9dff716e6c79'"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"what is role of c language and php while creating ai agentic pattern?\"}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43511af",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who is a first president of USA?\"}\n",
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3693127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
